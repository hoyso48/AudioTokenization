{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input shape: torch.Size([1, 10, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal input shape:\u001b[39m\u001b[33m\"\u001b[39m, dummy_input.shape)\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Merge the top 2 most similar pairs. This should link (0,1) and (1,2).\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Resulting groups should be {0,1,2}, {3}, {4,5}, {6}, {7}, {8}, {9}\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# This means 10 tokens become 7 tokens.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m merged_output, unmerge_info = \u001b[43madjacent_chained_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerged output shape:\u001b[39m\u001b[33m\"\u001b[39m, merged_output.shape)\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnmerge info (group ID for each original token):\u001b[39m\u001b[33m\"\u001b[39m, unmerge_info)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36madjacent_chained_merge\u001b[39m\u001b[34m(x, r)\u001b[39m\n\u001b[32m     72\u001b[39m group_counts = torch.zeros(B, num_merged_tokens, \u001b[32m1\u001b[39m, device=device, dtype=x.dtype)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Use scatter_add to sum up token values and counts for each group\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# The `inverse_indices` directly tell us where each original token should go.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m x_out.scatter_add_(\u001b[32m1\u001b[39m, \u001b[43minverse_indices\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m, x)\n\u001b[32m     77\u001b[39m group_counts.scatter_add_(\u001b[32m1\u001b[39m, inverse_indices.unsqueeze(-\u001b[32m1\u001b[39m), torch.ones_like(x[..., :\u001b[32m1\u001b[39m]))\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Average the values in each group\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "\n",
    "def adjacent_chained_merge(\n",
    "    x: torch.Tensor,\n",
    "    r: int,\n",
    ") -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Merges `r` most similar adjacent token pairs, allowing for chained merging.\n",
    "    If (A,B) and (B,C) are both selected, they become a single group (A,B,C).\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor of shape [B, N, C].\n",
    "        r (int): The number of merge operations (links) to perform.\n",
    "                 The final number of removed tokens might be >= r.\n",
    "\n",
    "    Returns:\n",
    "        The merged tensor and information needed for unmerging.\n",
    "    \"\"\"\n",
    "    if r <= 0:\n",
    "        return x, (None, None)\n",
    "\n",
    "    B, N, C = x.shape\n",
    "    device = x.device\n",
    "    r = min(r, N - 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # --- 1. Calculate Similarity ---\n",
    "        left_tokens = x[:, :-1]\n",
    "        right_tokens = x[:, 1:]\n",
    "        sim = (F.normalize(left_tokens, p=2, dim=-1) * F.normalize(right_tokens, p=2, dim=-1)).sum(dim=-1)\n",
    "\n",
    "        # --- 2. Select top `r` links ---\n",
    "        _, top_indices = torch.topk(sim, r, dim=-1)\n",
    "\n",
    "        # --- 3. Find Connected Components to form groups ---\n",
    "        # Each token is initially in its own group.\n",
    "        # Group IDs are 0, 1, 2, ..., N-1.\n",
    "        group_ids = torch.arange(N, device=device).unsqueeze(0).expand(B, -1)\n",
    "\n",
    "        # For each selected link (A, B), we merge their groups.\n",
    "        # We do this iteratively by setting group_id(B) = group_id(A).\n",
    "        # To make this stable, we always merge the group with the larger ID into the one with the smaller ID.\n",
    "        # This requires a loop, but it's over `r` which is usually small.\n",
    "        # For a fully vectorized but more complex version, a union-find algorithm would be needed.\n",
    "        # This loop-based approach is easier to understand.\n",
    "        for i in range(r):\n",
    "            idx = top_indices[:, i]\n",
    "            # Use batch-aware indexing\n",
    "            batch_indices = torch.arange(B, device=device)\n",
    "            left_ids = group_ids[batch_indices, idx]\n",
    "            right_ids = group_ids[batch_indices, idx + 1]\n",
    "            \n",
    "            # Find min and max IDs for stable merging\n",
    "            min_ids = torch.min(left_ids, right_ids)\n",
    "            max_ids = torch.max(left_ids, right_ids)\n",
    "\n",
    "            # Merge groups: all tokens with max_id now get min_id\n",
    "            for b in range(B):\n",
    "                group_ids[b, group_ids[b] == max_ids[b]] = min_ids[b]\n",
    "        \n",
    "        # Find the final unique group IDs and assign new sequential indices\n",
    "        # `unique_ids` will be sorted. `inverse_indices` maps each original token to its new group index.\n",
    "        unique_ids, inverse_indices = torch.unique(group_ids, return_inverse=True, dim=-1)\n",
    "        num_merged_tokens = unique_ids.shape[-1]\n",
    "        \n",
    "        # --- 4. Execute Merge ---\n",
    "        # Create output tensor for the merged tokens\n",
    "        x_out = torch.zeros(B, num_merged_tokens, C, device=device, dtype=x.dtype)\n",
    "        # Create a tensor to count the size of each group for averaging\n",
    "        group_counts = torch.zeros(B, num_merged_tokens, 1, device=device, dtype=x.dtype)\n",
    "\n",
    "        # Use scatter_add to sum up token values and counts for each group\n",
    "        # The `inverse_indices` directly tell us where each original token should go.\n",
    "        x_out.scatter_add_(1, inverse_indices.unsqueeze(-1).expand(-1, -1, C), x)\n",
    "        group_counts.scatter_add_(1, inverse_indices.unsqueeze(-1), torch.ones_like(x[..., :1]))\n",
    "\n",
    "        # Average the values in each group\n",
    "        x_out /= group_counts\n",
    "\n",
    "        # For unmerging, we need to know which final token corresponds to which original tokens.\n",
    "        # The `inverse_indices` tensor already contains this mapping.\n",
    "        unmerge_info = inverse_indices\n",
    "\n",
    "    return x_out, unmerge_info\n",
    "\n",
    "\n",
    "def adjacent_chained_unmerge(x: torch.Tensor, unmerge_info: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Unmerges tokens that were merged with the chained method.\n",
    "    \"\"\"\n",
    "    if unmerge_info is None:\n",
    "        return x\n",
    "    \n",
    "    B, _, C = x.shape\n",
    "    \n",
    "    # `unmerge_info` maps each original position to its merged group index.\n",
    "    # We can use `gather` to broadcast the merged token values back to their original positions.\n",
    "    unmerged_output = x.gather(1, unmerge_info.unsqueeze(-1).expand(-1, -1, C))\n",
    "    \n",
    "    return unmerged_output\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 1\n",
    "    seq_len = 10\n",
    "    channels = 2\n",
    "    \n",
    "    dummy_input = torch.randn(batch_size, seq_len, channels)\n",
    "    # Make A,B,C similar: (0,1), (1,2)\n",
    "    dummy_input[:, 1, :] = dummy_input[:, 0, :] + 0.1\n",
    "    dummy_input[:, 2, :] = dummy_input[:, 1, :] + 0.15\n",
    "    # Make D,E similar: (4,5)\n",
    "    dummy_input[:, 5, :] = dummy_input[:, 4, :] + 0.2\n",
    "    \n",
    "    print(\"Original input shape:\", dummy_input.shape)\n",
    "    \n",
    "    # Merge the top 2 most similar pairs. This should link (0,1) and (1,2).\n",
    "    # Resulting groups should be {0,1,2}, {3}, {4,5}, {6}, {7}, {8}, {9}\n",
    "    # This means 10 tokens become 7 tokens.\n",
    "    merged_output, unmerge_info = adjacent_chained_merge(dummy_input, r=3)\n",
    "    \n",
    "    print(\"Merged output shape:\", merged_output.shape)\n",
    "    print(\"Unmerge info (group ID for each original token):\", unmerge_info)\n",
    "    \n",
    "    unmerged_output = adjacent_chained_unmerge(merged_output, unmerge_info)\n",
    "    print(\"Unmerged output shape:\", unmerged_output.shape)\n",
    "    \n",
    "    # Verification\n",
    "    # The values for tokens 0, 1, 2 should be the same and equal to their average\n",
    "    original_avg_012 = dummy_input[:, [0,1,2], :].mean(dim=1)\n",
    "    print(\"\\nVerification for group {0,1,2}:\")\n",
    "    print(\"Original Average:\", original_avg_012)\n",
    "    print(\"Unmerged value at pos 0:\", unmerged_output[:, 0, :])\n",
    "    print(\"Unmerged value at pos 2:\", unmerged_output[:, 2, :])\n",
    "    print(\"All three positions match:\", torch.allclose(unmerged_output[:, 0, :], unmerged_output[:, 1, :]) and torch.allclose(unmerged_output[:, 1, :], unmerged_output[:, 2, :]))\n",
    "    print(\"Value matches original average:\", torch.allclose(unmerged_output[:, 0, :], original_avg_012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoyso_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
